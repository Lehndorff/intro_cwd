---
title: "Project 3"
author: "Hendrik Orem, Ph.D., with thanks to Jameson Watts"
date: "03/16/2023"
output:
  pdf_document:
    df_print: kable
    fig_width: 11
    fig_height: 8
  html_document:
    df_print: paged
---





## Setup
```{r setup, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(tidyverse)
library(tidytext)
library(caret)
library(fastDummies)
library(randomForest)
# https://www.openml.org/d/1590

tourney_data <- read_csv("tourney_data.csv") %>% 
  mutate(rank=log2(rank)) %>% # converts 1,2,4,8,16, etc to 0,1,2,3,4
  select(-Season,-class,-`Coach(es)`,-`NCAA Tournament`) %>% #either not helpful, or duplicative
  filter(!is.na(Pts_for)) %>% #removes 1 case
  mutate(across("AP Pre":"AP Final",function(x){ifelse(is.na(x),"Not 25",paste("Top",ceiling(x/5)*5))})) %>% #data cleaning
  mutate(across(Conf_W:Conf_Pct,function(x){ifelse(is.na(x),0,x)})) #%>% #fill missing info

skimr::skim(tourney_data)

tourney_data2<-tourney_data %>%
  fastDummies::dummy_cols(remove_selected_columns = T) %>% #simple dummy cols
  arrange(tourn_year) %>% mutate(lag_rank=lag(rank)) %>% mutate(lag_rank=ifelse(is.na(lag_rank),6,lag_rank)) %>% #how did the team do last year
  mutate(rank=as.numeric(rank<=4))# <=4 = Did team make the sweet 16 (one of the final 2^4 teams)
table(tourney_data2$rank)
```

## Some questions about the data

Please try at least a few of the following:

* Run PCA on the dataset. How many principal components do you need to explain half the variation? 
* Can you give some interpretation of the principal components?
* Look at the scree plot. How many PCs would you choose based on that?
* Are the first few Principal Components good predictors of income_above_50k?
* How well can you predict income_above_50k using the first 5 or 6 principal components? How about only the first 2?
* Can you gain any insights into the data based on k-means clustering? 
* Can you visualize and interpret some or all of your clusters?
* Using any and all techniques we have learned, build the best predictive model for income_above_50k that you can. What are your best features? What model did you use? What interpretations can you draw?
* What metric can you use to assess model performance? Why is that a good choice of metric in this case?
* What are some key insights you found through your analysis?

Please remember: a statement like "PC2 is not a meaningful predictor for our modeling problem" is a great insight; sometimes things don't work!

10 pts PCA

* analysis and interpretation of factor loadings
* discussion of scree plot and/or analysis of some density plots of PCs
* meaningful interpretation / discussion of conclusions 

```{r}
pr_tourney <- prcomp(x = select(tourney_data2,-rank), scale = T, center = T)
summary(pr_tourney)

screeplot(pr_tourney, type = "lines")

rownames_to_column(as.data.frame(pr_tourney$rotation)) %>% 
  select(1:4) %>% 
  filter(abs(PC1) >= 0.25 | abs(PC2) >= 0.25 | abs(PC3) >= 0.25) %>% 
  View()

prc <- bind_cols(select(tourney_data2,rank),as.data.frame(pr_tourney$x)) %>% 
  select(1:4) %>% 
  rename("strong_record_seed" = PC1) %>% 
  rename("struggle_in_conf" = PC2) %>% 
  rename("defense_focus" = PC3) 
head(prc)

prc %>% 
  pivot_longer(cols = -rank,names_to = "component",values_to = "loading") %>% 
  ggplot(aes(x=loading, fill=factor(rank),group=rank))+
  geom_density(alpha=0.5)+
  facet_wrap(.~component,scales = "free_y")


```
Screeplot suggests that the ideal number of components is three. 


10 pts k-means

* discussion for choosing number of clusters
* analysis of cluster centers
* bivariate chart(s) against meaningful variables and/or analysis of density plots
* meaningful interpretation / discussion of conclusions 

```{r}
# names(tourney_data2)

tourney_cl = select(tourney_data2,-rank)

kclust3 <- kmeans(tourney_cl, centers = 3)

tourney_clustered3 = augment(kclust3, tourney_data2)

# tourney_clustered3 %>% select(rank, .cluster)

tourney_clustered3 %>% pivot_longer(c(rank),names_to = "feature") %>%
  ggplot(aes(value, fill=.cluster))+
  geom_density(alpha=0.3)+
  facet_wrap(~feature)

kclust4 <- kmeans(tourney_cl, centers = 4)

tourney_clustered4 = augment(kclust4, tourney_data2)

# tourney_clustered4 %>% select(rank, .cluster)

tourney_clustered4 %>% pivot_longer(c(rank),names_to = "feature") %>%
  ggplot(aes(value, fill=.cluster))+
  geom_density(alpha=0.3)+
  facet_wrap(~feature)

kclust5 <- kmeans(tourney_cl, centers = 5)

tourney_clustered5 = augment(kclust5, tourney_data2)

# tourney_clustered5 %>% select(rank, .cluster)

tourney_clustered5 %>% pivot_longer(c(rank),names_to = "feature") %>%
  ggplot(aes(value, fill=.cluster))+
  geom_density(alpha=0.3)+
  facet_wrap(~feature)

#four clusters has the most distinct distributions; cluster 2 are the biggest losers,  clusters 1 & 4 mostly losing, and cluster 3 winners
tourney_clustered4 %>% group_by(rank, .cluster) %>% summarize(n=n())

kclusts <- tibble(k = 1:9) %>%
mutate(
kclust = map(k, ~kmeans(tourney_cl, .x)),
glanced = map(kclust, glance),
augmented = map(kclust, augment, tourney_cl)
)

clusterings <- kclusts %>%
unnest(glanced, .drop = TRUE)
ggplot(clusterings, aes(k, tot.withinss)) +
geom_line() 


#hierarchical clustering

hclustr <- hclust(d=dist(tourney_cl))
summary(hclustr)

plot(hclustr)
abline(h=3, col="red")

cluster <- cutree(hclustr, k=3)
tourney_hcl <- tourney_data2 %>%
add_column(cluster) %>%
mutate(cluster=as_factor(cluster))

tourney_hcl %>% group_by(rank, cluster) %>% summarize(n=n())

tourney_hcl %>%
pivot_longer(c(rank),names_to = "feature") %>%
ggplot(aes(value, fill=cluster))+
geom_density(alpha=0.3)+
facet_wrap(~feature)


```


10 pts supervised learning

* feature engineering / selection, whether with PCA or otherwise
* interpretation of variable importance, coefficients if applicable
* justification of choice of metric
* discussion of choice or tuning of hyperparameters, if any
* meaningful discussion of predictive power and conclusions from model

```{r}
table(prc$rank==tourney_clustered5$rank) #Check that prc and tourney_clustered4 are ordered the same

full_tourney_features<-tourney_clustered5 %>% 
  cbind(prc %>% select(-rank)) %>% 
  select("rank","SRS","strong_record_seed","Ovr_W","SOS","Seed","tourn_year",
       "struggle_in_conf","Ovr_Pct","defense_focus","Pts_against","Pts_for","Ovr_L",
       "Conf_Pct","Conf_W","AP Final_Not 25","lag_rank","Conf_L",
       "team_Syracuse Orange Men's Basketball","AP High_Top 5","AP Pre_Not 25"
       )

test_2023<-full_tourney_features %>% 
  filter(tourn_year==2023)

full_tourney_features<-full_tourney_features %>% 
  filter(tourn_year!=2023)
  
train<-full_tourney_features %>% 
  group_by(rank) %>% #Sample within outcomes to ensure representativeness
  sample_frac(.8)
test<-full_tourney_features %>% 
  anti_join(train)

control <- trainControl(method = "boot", number = 1)
# ctrl <- trainControl(method = "cv", number = 5)
fit_rf <- train(rank ~ .,
             data = train,
             method = "rf",
             trControl = control)

plot(varImp(fit_rf),top=20)

pred <- predict(fit_rf, newdata=test)

best_thresh<-function(x){
  pred2<-as.numeric(pred>x)
  output<-as.numeric(confusionMatrix(factor(pred2),factor(test$rank))$overall[2])
  return(output)
}

cutoff<-data.frame(thresh=seq(0,1,.01)) %>%
  mutate(best=sapply(thresh,best_thresh)) %>%
  filter(best==max(best)) %>%
  pull(thresh)
pred2<-as.numeric(pred>cutoff[1])

confusionMatrix(factor(pred2),factor(test$rank))

pred <- predict(fit_rf, newdata=test_2023)


nth_val<-sort(pred,decreasing = T)[2^4] #For current year, should only predicted as many teams as is actually possible
pred2<-as.numeric(pred>=nth_val)
table(pred2)

confusionMatrix(factor(pred2),factor(test_2023$rank))

prediction_output<-tourney_data %>% 
  filter(tourn_year==2023) %>% 
  mutate(rank=as.numeric(rank<=4)) %>% # <=4 = Did team make the sweet 16 (one of the final 2^4 teams)
  mutate(prediction=pred2) %>% 
  select(team, Seed, rank, prediction) %>% 
  mutate(correct=rank==prediction)


```


Please be prepared to 

* Submit your Rmd + compiled html or pdf, *and*
* Present your findings to the class in a compelling way, speaking for 10 minutes or so. You don't need to cover everything in your analysis that you submit to me, focus on the fun / interesting / compelling highlights or challenges.
